{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06.2020 - Jeff Vestal @ Elastic\n",
    "# version 1.1\n",
    "\n",
    "# Created with v7.8 of elasticsearch\n",
    "# eland repo https://github.com/elastic/eland\n",
    "# Model Training borrowed from - https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier_example/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set elasticsearch cluster url and creds from .env file\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "es_url=os.getenv('ES_URL')\n",
    "es_user=os.getenv('ES_USER')\n",
    "es_pass=os.getenv('ES_PASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the library with the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load scikit's random forest classifier library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load eland\n",
    "import eland as ed\n",
    "\n",
    "# Load numpy\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Don't do this\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object called iris with the iris data\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "# Create a dataframe with the four feature variables\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# View the top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column with the species names, this is what we are going to try to predict\n",
    "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "\n",
    "# View the top 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that for each row, generates a random number between 0 and 1, and\n",
    "# if that value is less than or equal to .75, then sets the value of that cell as True\n",
    "# and false otherwise. This is a quick and dirty way of randomly assigning some rows to\n",
    "# be used as the training data and some as the test data.\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "\n",
    "# View the top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new dataframes, one with the training rows, one with the test rows\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "\n",
    "# Show the number of observations for the test and training dataframes\n",
    "print('Number of observations in the training data:', len(train))\n",
    "print('Number of observations in the test data:',len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the feature column's names\n",
    "features = df.columns[:4]\n",
    "\n",
    "# View features\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['species'] contains the actual species names. Before we can use it,\n",
    "# we need to convert each species name into a digit. So, in this case there\n",
    "# are three species, which have been coded as 0, 1, or 2.\n",
    "y, labels = pd.factorize(train['species'])\n",
    "\n",
    "# View target\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(train[features], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Classifier we trained to the test data (which, remember, it has never seen before)\n",
    "clf.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the predicted probabilities of the first 10 observations\n",
    "clf.predict_proba(test[features])[0:10]\n",
    "\n",
    "# [probability belongs to first class, probability belongs to second class, predicted class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create actual english names for the plants for each predicted plant class\n",
    "preds = iris.target_names[clf.predict(test[features])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the PREDICTED species for the first five observations\n",
    "preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the ACTUAL species for the first five observations\n",
    "test['species'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "pd.crosstab(test['species'], preds, rownames=['Actual Species'], colnames=['Predicted Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a list of the features and their importance scores\n",
    "list(zip(train[features], clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eland and Elastic time\n",
    "from eland.ml import ImportedMLModel\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client.ml import MlClient\n",
    "from elasticsearch.client import IngestClient\n",
    "from elasticsearch.client import IndicesClient\n",
    "from elasticsearch.client.enrich import EnrichClient\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "from datetime import datetime\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create es connection\n",
    "es = Elasticsearch(es_url, http_auth=(es_user,es_pass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialise the trained RandomForestClassifier model to Elasticsearch\n",
    "\n",
    "# pick short feature names for the docs\n",
    "feature_names = ['sl', 'sw', 'pl', 'pw']\n",
    "\n",
    "# name model\n",
    "model_id = \"jeffs-rfc-flower-type\"\n",
    "\n",
    "# load model into elasticsearch\n",
    "es_model = ImportedMLModel(es, model_id, clf, feature_names, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify model exists in es\n",
    "MlClient.get_trained_models(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test out the pipeline and new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure ingest pipeline with inference processor using our model\n",
    "body = {\n",
    "  \"pipeline\": {\n",
    "    \"processors\": [\n",
    "      {\n",
    "        \"inference\": {\n",
    "          \"model_id\": model_id,\n",
    "          \"inference_config\": {\n",
    "            \"classification\": {}\n",
    "          },\n",
    "          \"field_map\": {}\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"docs\": [\n",
    "    {\n",
    "      \"_source\": {\n",
    "        \"sl\" : 4.2,\n",
    "        \"sw\": 3.9,\n",
    "        \"pl\": 1.9,\n",
    "        \"pw\": 0.4\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# simulate ingest pipeline\n",
    "IngestClient.simulate(es, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets include an english name to convert the predicted value back to english flower name\n",
    "\n",
    "# set up an enrich index\n",
    "\n",
    "# create docs mapping serialized values -> english name\n",
    "mapping_index_name = model_id + '_mapping'\n",
    "mapping_docs =[]\n",
    "now = datetime.now()\n",
    "\n",
    "for pos, name in enumerate(labels.categories):\n",
    "    mapping_docs.append({\"_index\": mapping_index_name,\n",
    "                         'mapped_value': pos,\n",
    "                         'flower_name': name,\n",
    "                         'updated_ts': now})\n",
    "\n",
    "\n",
    "# index mapping into es\n",
    "res = bulk(es, mapping_docs)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify mapping docs are in the index\n",
    "res = es.search(index=mapping_index_name, body={\"query\": {\"match_all\": {}}})\n",
    "for doc in res['hits']['hits']:\n",
    "    print ('Predicted value: %s -> Flower Name: %s'% (doc['_source']['mapped_value'], doc['_source']['flower_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create enrich policy\n",
    "policy_name = model_id + '_enrich'\n",
    "\n",
    "#delete existing policy\n",
    "for p in EnrichClient.get_policy(es, name=policy_name)['policies']:\n",
    "    if policy_name == p['config']['match']['name']:\n",
    "        print('deleting existing policy')\n",
    "        EnrichClient.delete_policy(es, name=policy_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put enrich policy\n",
    "policy = { \"match\" :{\n",
    "        \"indices\": mapping_index_name,\n",
    "        \"match_field\": 'mapped_value',\n",
    "        \"enrich_fields\": [\"flower_name\"]\n",
    "            }\n",
    "        }\n",
    "\n",
    "EnrichClient.put_policy(es, name=policy_name, body=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify enrich policy\n",
    "EnrichClient.get_policy(es, name=policy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute enrich policy\n",
    "EnrichClient.execute_policy(es, name=policy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ingest pipeline / inference pipeline with the additional enrich processor\n",
    "processors = [\n",
    "      {\n",
    "        \"inference\": {\n",
    "          \"model_id\": model_id,\n",
    "          \"inference_config\": {\n",
    "            \"classification\": {}\n",
    "          },\n",
    "          \"field_map\": {}\n",
    "        }\n",
    "      },\n",
    "        {\n",
    "         \"enrich\": {\n",
    "             'policy_name': policy_name,\n",
    "             'field' : 'ml.inference.predicted_value',\n",
    "             'target_field' : 'ml.inference.predicted_name',\n",
    "                    \"tag\": \"enriched\"\n",
    "\n",
    "         }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "body = {\n",
    "  \"pipeline\": {\n",
    "    \"processors\": processors\n",
    "  },\n",
    "  \"docs\": [\n",
    "    {\n",
    "      \"_source\": {\n",
    "        \"sl\" : 4.2,\n",
    "        \"sw\": 3.9,\n",
    "        \"pl\": 1.9,\n",
    "        \"pw\": 0.4\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# simulate ingest pipeline\n",
    "IngestClient.simulate(es, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the pipeline for use in prod\n",
    "pipeline_name = model_id + '_ingest_pipeline'\n",
    "body = {\n",
    "    'description': 'predict flower type',\n",
    "    'processors': processors\n",
    "}\n",
    "\n",
    "IngestClient.put_pipeline(es, id=pipeline_name, body=body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify pipeline\n",
    "IngestClient.get_pipeline(es, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index template with our new pipeline as the default pipeline\n",
    "\n",
    "settings = {\n",
    "  \"index_patterns\": [\"flower_measurements-*\"],\n",
    "  \"settings\": {\n",
    "    \"default_pipeline\": \"jeffs-rfc-flower-type_ingest_pipeline\"\n",
    "  }\n",
    "}\n",
    "\n",
    "template_name = 'flowers_measurement'\n",
    "IndicesClient.put_template(es, name=template_name, body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify  template\n",
    "IndicesClient.get_template(es, name=template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put a new document with different (definitely real) measurements\n",
    "\n",
    "new_flower = {\n",
    "        \"sl\" : 4.2,\n",
    "        \"sw\": 3.9,\n",
    "        \"pl\": 11.9,\n",
    "        \"pw\": 10.4,\n",
    "        'updated_ts': now\n",
    "      }\n",
    "\n",
    "final_leg_index = 'flower_measurements-magic'\n",
    "new_doc = es.index(index=final_leg_index, body=new_flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the doc was created\n",
    "new_doc['result'], new_doc['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out what the flower was predicted to be with the _source and a nice human readable output!\n",
    "res = es.get(index=final_leg_index,id=new_doc['_id'])\n",
    "pprint(res['_source'])\n",
    "print('\\nThis flower is predicted to be a %s !' % res['_source']['ml']['inference']['predicted_name']['flower_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "\n",
    "\n",
    "IngestClient.delete_pipeline(es, id=pipeline_name)\n",
    "IndicesClient.delete_template(es, name=template_name)\n",
    "EnrichClient.delete_policy(es, name=policy_name)\n",
    "es.delete_by_query(index=final_leg_index, body={\"query\": {\"match_all\": {}}})\n",
    "es.delete_by_query(index=mapping_index_name, body={\"query\": {\"match_all\": {}}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
